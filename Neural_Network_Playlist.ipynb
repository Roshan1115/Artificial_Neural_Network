{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOXWdY+Zs01KtnunX8zkf9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roshan1115/Artificial_Neural_Network/blob/main/Neural_Network_Playlist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lswug4fwznoY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# X = [[1, 2, 3, 2.5],\n",
        "#      [2.0, 5.0, -1.0, 2.0],\n",
        "#      [-1.5, 2.7, 3.3, -0.8]]\n",
        "\n",
        "\n",
        "#class for feedforward without activation function\n",
        "\n",
        "class layer_dense:\n",
        "  def __init__(self, n_input, n_neuron):  #neurons of hidden layer\n",
        "    self.weights = 0.10 * np.random.randn(n_input, n_neuron)\n",
        "    self.bias = np.zeros((1,n_neuron))\n",
        "  \n",
        "  def forward(self, input):\n",
        "    self.output = np.dot(input, self.weights) + self.bias\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation Functions\n",
        "\n",
        "class Activation_ReLU:\n",
        "  def forward(self, inputs):\n",
        "    self.output = np.maximum(0, inputs)\n",
        "\n",
        "\n",
        "class Activation_SoftMax:\n",
        "  def forward(self, inputs):\n",
        "    self.exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
        "    self.probability = self.exp_values / np.sum(self.exp_values, axis=1, keepdims=True)\n",
        "    self.output = self.probability\n"
      ],
      "metadata": {
        "id": "-GKRj9F52w-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "\n",
        "class Loss:\n",
        "  def calculate(self, output, y):\n",
        "    sample_loss = self.forward(output, y)\n",
        "    data_loss = np.mean(sample_loss)\n",
        "    return sample_loss\n",
        "\n",
        "\n",
        "\n",
        "class Loss_CategoricalCrossEntropy(Loss):\n",
        "  def forward(self, y_pred, y_true):\n",
        "    samples = len(y_pred)\n",
        "    y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "    if len(y_true.shape) == 1:\n",
        "      correct_confidence = y_pred_clipped[range(samples), y_true]\n",
        "\n",
        "    elif len(y_true.shape) == 2:\n",
        "      correct_confidence = np.sum(y_pred_clipped * y_true, axis = 1)\n",
        "      \n",
        "    negative_log_likelihood = - np.log(correct_confidence)\n",
        "    return negative_log_likelihood\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BdhYCifJNiOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# spiral data creation\n",
        "\n",
        "def create_data(points, classes):\n",
        "  N = points\n",
        "  D = 2\n",
        "  K = classes\n",
        "  X = np.zeros((N*K,D)) \n",
        "  y = np.zeros(N*K, dtype='uint8') \n",
        "  for j in range(K):\n",
        "    ix = range(N*j,N*(j+1))\n",
        "    r = np.linspace(0.0,1,N) # radius\n",
        "    t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta\n",
        "    X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
        "    y[ix] = j\n",
        "  return X,y\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X, y = create_data(100,3)\n",
        "\n",
        "# plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n",
        "dense1 = layer_dense(2, 3)\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "dense2 = layer_dense(3, 3)\n",
        "activation2 = Activation_SoftMax()\n",
        "\n",
        "dense1.forward(X)\n",
        "activation1.forward(dense1.output)\n",
        "\n",
        "dense2.forward(activation1.output)\n",
        "activation2.forward(dense2.output)\n",
        "\n",
        "\n",
        "print(\"Predicted values\")\n",
        "print(activation2.output[:5])\n",
        "\n",
        "print(\"\\nActual class of each point\")\n",
        "print(y)\n",
        "\n",
        "loss_function = Loss_CategoricalCrossEntropy()\n",
        "loss = loss_function.calculate(activation2.output, y)\n",
        "\n",
        "print(\"\\nLoss is \")\n",
        "print(loss[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVnrtM44_K2k",
        "outputId": "9cb74acf-b2c8-477a-a263-6d35a5379d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted values\n",
            "[[0.33333333 0.33333333 0.33333333]\n",
            " [0.33335607 0.33332304 0.33332089]\n",
            " [0.33337862 0.33331283 0.33330855]\n",
            " [0.33340383 0.33330133 0.33329484]\n",
            " [0.33342841 0.33329014 0.33328145]]\n",
            "\n",
            "Actual class of each point\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2]\n",
            "\n",
            "Loss is \n",
            "[1.09861229 1.09854408 1.09847643 1.09840082 1.0983271 ]\n"
          ]
        }
      ]
    }
  ]
}